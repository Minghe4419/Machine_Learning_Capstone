{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "81f08514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(12556949)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "f686f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, euclidean_distances\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from torch import nn\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "0bfeca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('musicData.csv')\n",
    "df.drop(['instance_id', 'artist_name', 'track_name', 'obtained_date'], axis = 1, inplace=True)\n",
    "df.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "580abfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data in column 'key'\n",
    "df['key'] = pd.factorize(df['key'])[0]\n",
    "df['key'].replace(-1, np.nan, inplace=True)\n",
    "key_mean = df['key'].mean()\n",
    "df['key'].fillna(key_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "16e357f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn column 'mode' to 1 or 0\n",
    "df['mode'].replace('Major', 1, inplace=True)\n",
    "df['mode'].replace('Minor', 0, inplace=True)\n",
    "df.dropna(subset=['mode'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "29f6eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['music_genre'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "efb940ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(-1,np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "16f6807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_ms'].fillna(df['duration_ms'].mean(skipna=True), inplace=True)\n",
    "df['tempo'].fillna(df['tempo'].astype(float).mean(skipna=True), inplace=True)\n",
    "df['music_genre'] = pd.factorize(df['music_genre'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "bb5cc355",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 500\n",
    "genres = df['music_genre'].unique()\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "for genre in genres:\n",
    "    # Split data for this genre\n",
    "    genre_data = df[df['music_genre'] == genre].copy()\n",
    "    train, test = train_test_split(genre_data, test_size=test_size)\n",
    "    train_data.append(train)\n",
    "    test_data.append(test)\n",
    "\n",
    "# Combine train and test data for each genre\n",
    "train_data = pd.concat(train_data)\n",
    "test_data = pd.concat(test_data)\n",
    "\n",
    "# Separate the target variable from the features\n",
    "X_train = train_data.drop('music_genre', axis=1)\n",
    "y_train = train_data['music_genre']\n",
    "X_test = test_data.drop('music_genre', axis=1)\n",
    "y_test = test_data['music_genre']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "9cf4edeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.421</td>\n",
       "      <td>262533.000000</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-9.179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3020</td>\n",
       "      <td>162.179</td>\n",
       "      <td>0.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.628</td>\n",
       "      <td>368277.000000</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>-5.443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>119.952961</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.888</td>\n",
       "      <td>355440.000000</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>-8.711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>119.952961</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.672</td>\n",
       "      <td>265250.000000</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>-4.514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>140.026</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.334</td>\n",
       "      <td>174545.000000</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>-6.126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>78.711</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46608</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.734</td>\n",
       "      <td>155063.000000</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>-4.550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>149.977</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45629</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.714</td>\n",
       "      <td>245503.541466</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>-5.834</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>132.843</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48096</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.851</td>\n",
       "      <td>193907.000000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>-9.775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>149.98</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47946</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.881</td>\n",
       "      <td>237733.000000</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>-5.401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>106.054</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47857</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.813</td>\n",
       "      <td>245503.541466</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>-10.530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>77.531</td>\n",
       "      <td>0.184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       popularity  acousticness  danceability    duration_ms  energy  \\\n",
       "1474         41.0      0.076400         0.421  262533.000000   0.944   \n",
       "3758         38.0      0.013800         0.628  368277.000000   0.719   \n",
       "1056         51.0      0.004920         0.888  355440.000000   0.780   \n",
       "3822         45.0      0.000672         0.672  265250.000000   0.897   \n",
       "1622         29.0      0.001910         0.334  174545.000000   0.803   \n",
       "...           ...           ...           ...            ...     ...   \n",
       "46608        50.0      0.012100         0.734  155063.000000   0.626   \n",
       "45629        50.0      0.178000         0.714  245503.541466   0.709   \n",
       "48096        60.0      0.072200         0.851  193907.000000   0.405   \n",
       "47946        50.0      0.042300         0.881  237733.000000   0.889   \n",
       "47857        52.0      0.060300         0.813  245503.541466   0.366   \n",
       "\n",
       "       instrumentalness  key  liveness  loudness  mode  speechiness  \\\n",
       "1474           0.815000  2.0    0.1190    -9.179   1.0       0.3020   \n",
       "3758           0.095100  2.0    0.2060    -5.443   1.0       0.0410   \n",
       "1056           0.356000  0.0    0.0675    -8.711   0.0       0.0797   \n",
       "3822           0.000618  4.0    0.0707    -4.514   1.0       0.4160   \n",
       "1622           0.005800  0.0    0.1150    -6.126   0.0       0.1160   \n",
       "...                 ...  ...       ...       ...   ...          ...   \n",
       "46608          0.000043  7.0    0.3730    -4.550   1.0       0.2560   \n",
       "45629          0.000000  9.0    0.0375    -5.834   1.0       0.1150   \n",
       "48096          0.000001  3.0    0.1080    -9.775   1.0       0.2050   \n",
       "47946          0.000001  5.0    0.1080    -5.401   1.0       0.0944   \n",
       "47857          0.000000  7.0    0.0864   -10.530   0.0       0.3370   \n",
       "\n",
       "            tempo  valence  \n",
       "1474      162.179    0.222  \n",
       "3758   119.952961    0.371  \n",
       "1056   119.952961    0.746  \n",
       "3822      140.026    0.360  \n",
       "1622       78.711    0.132  \n",
       "...           ...      ...  \n",
       "46608     149.977    0.542  \n",
       "45629     132.843    0.933  \n",
       "48096      149.98    0.292  \n",
       "47946     106.054    0.492  \n",
       "47857      77.531    0.184  \n",
       "\n",
       "[45000 rows x 13 columns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "2ceca273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensionality reduction and clustering\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# Determine number of components for PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "sum(pca.explained_variance_ >1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "9345fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_pca_train = pca.fit_transform(X_train_scaled)\n",
    "X_pca_test = pca.fit_transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "19c367f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diaoxinqing/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/Users/diaoxinqing/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=7, random_state = 20)\n",
    "X_clustered_train = kmeans.fit_transform(X_pca_train)\n",
    "X_clustered_test = kmeans.fit_transform(X_pca_test)\n",
    "y_pred = kmeans.predict(X_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "905ca364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5157665333333332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_clustered_train, y_train)\n",
    "y_prob = dtc.predict_proba(X_clustered_test)\n",
    "auc = roc_auc_score(y_test, y_prob, multi_class='ovo')\n",
    "print('AUC:', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "41209318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 999, [LOSS]: 1.684719, [ACCURACY]: 0.355\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "learning_rate = 1e-1\n",
    "lambda_l2 = 1e-3\n",
    "D = X_clustered_train.shape[1]\n",
    "H = 100\n",
    "C = len(np.unique(y_train))\n",
    "\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_clustered_train.astype(np.float32))\n",
    "X_val_tensor = torch.tensor(X_clustered_test.astype(np.float32))\n",
    "Y_train_tensor = torch.tensor(y_train.values).long()\n",
    "Y_val_tensor = torch.tensor(y_test.values).long()\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D, H),\n",
    "    nn.Linear(H, H),\n",
    "    nn.Linear(H, C)\n",
    ")\n",
    "# nn package has a variety of loss functions already implemented\n",
    "# we use cross entropy loss for our classification task\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# nn package also has a variety of optimization algorithms implemented\n",
    "# we use the stochastic gradient descent for our parameter updates\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=lambda_l2) # built-in L2\n",
    "\n",
    "# Training loop\n",
    "for t in range(1000):\n",
    "    \n",
    "    # Forward pass over the model to get the logits \n",
    "    y_pred = model(X_train_tensor)\n",
    "    \n",
    "    # Compute the loss and accuracy\n",
    "    loss = criterion(y_pred, Y_train_tensor)\n",
    "    score, predicted = torch.max(y_pred, 1)\n",
    "    acc = (Y_train_tensor == predicted).sum().float() / len(Y_train_tensor)\n",
    "    print(\"[EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % (t, loss.item(), acc))\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # reset (zero) the gradients before running the backward pass over the model\n",
    "    # we need to do this because the gradients get accumulated at the same place across iterations\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass to compute the gradient of loss w.r.t our learnable params (weights and biases)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update params\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "# Assuming you have trained a feedforward neural network and obtained predictions\n",
    "y_pred = model(X_val_tensor)  # Replace with your actual predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "60e4dc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5260558888888889\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming y_pred is a tensor of predicted class probabilities\n",
    "y_pred_softmax = F.softmax(y_pred, dim=1)\n",
    "auc = roc_auc_score(y_test, y_pred_softmax.detach().numpy(), multi_class='ovr')\n",
    "\n",
    "print(\"AUC: \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "017690e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.2494, -3.3737,  3.0332,  ..., -1.0874, -2.6503,  0.1268],\n",
       "        [ 2.8062, -4.3979,  2.7067,  ..., -0.5736, -3.0037,  1.3984],\n",
       "        [ 3.3601, -2.7442,  2.0167,  ..., -0.3300, -1.7702, -0.2195],\n",
       "        ...,\n",
       "        [ 3.5846, -2.2582,  2.9637,  ..., -0.9023, -2.0093, -1.3161],\n",
       "        [ 4.0706, -1.7015,  2.0832,  ..., -0.2830, -1.6218, -1.4422],\n",
       "        [ 3.7817, -2.2943,  2.3530,  ..., -0.6404, -2.0219, -0.8955]])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "af3da50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0937,  1.5280, -0.1485, -0.5701,  0.0079],\n",
       "        [-1.7533,  0.7126, -0.4108, -0.8609, -0.0078],\n",
       "        [ 0.3162,  1.4926,  0.7988,  1.4173,  1.8038],\n",
       "        ...,\n",
       "        [-1.0355, -1.6388,  0.5022,  0.2238,  1.1933],\n",
       "        [-2.2131, -2.3033, -0.3562,  1.3131,  0.2326],\n",
       "        [-0.7043, -1.1150,  0.4368,  1.6296, -0.1339]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "2000739a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "904f0f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 5])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "e305084d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45000])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503fdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
